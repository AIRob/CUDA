{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Texture Memory\n",
    "\n",
    "Texture memory는 GPU의 Texture HW를 이용하여, Index에 대해서 최적화된 동작을 할 수 있도록 해주는 read-only cache memory 입니다.\n",
    "\n",
    "CUDA의 Texture를 사용하는 방법은 크게 2가지로 나눌 수 있습니다. 하나는 Reference이며, 다른 하나는 Object입니다.\n",
    "각각의 사용법을 살펴보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sgemm_texture_reference.cu\n"
     ]
    }
   ],
   "source": [
    "%%file sgemm_texture_reference.cu\n",
    "\n",
    "#include \"sgemm.cuh\"\n",
    "\n",
    "texture<float, 1, cudaReadModeElementType> tex_A;\n",
    "texture<float, 1, cudaReadModeElementType> tex_B;\n",
    "\n",
    "__global__ void sgemm_texture(Matrix A, Matrix B, Matrix C, \n",
    "                      const float alpha, const float beta, \n",
    "                      const int width, const int height) {\n",
    "    int idx_x = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "    int idx_y = blockDim.y * blockIdx.y + threadIdx.y;\n",
    "    int idx = idx_y * width + idx_x;\n",
    "    \n",
    "    if (idx_x >= width || idx_y >= height)\n",
    "        return;\n",
    "    \n",
    "    float value = 0.f;\n",
    "    for (int e = 0; e < width; e++)\n",
    "        value = alpha * tex1Dfetch(tex_A, idx_y * width + e) * tex1Dfetch(tex_B, e * width + idx_x);\n",
    "    C.elements[idx] = value + beta * C.elements[idx];\n",
    "}\n",
    "\n",
    "void launch_sgemm_texture(Matrix &dA, Matrix &dB, Matrix &dC,\n",
    "                      const float alpha, const float beta, \n",
    "                      const int width, const int height) {    \n",
    "    // Bind the array to the texture reference\n",
    "    cudaBindTexture(0, tex_A, dA.elements, width * height * sizeof(float));\n",
    "    cudaBindTexture(0, tex_B, dB.elements, width * height * sizeof(float));\n",
    "    \n",
    "    dim3 blockDim(16, 16);\n",
    "    dim3 gridDim((width + blockDim.x - 1) / blockDim.x, (height + blockDim.y - 1) / blockDim.y);\n",
    "    sgemm_texture<<<gridDim, blockDim>>>(dA, dB, dC, alpha, beta, width, height);\n",
    "    \n",
    "    cudaUnbindTexture(tex_A);\n",
    "    cudaUnbindTexture(tex_B);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sgemm_texture_object.cu\n"
     ]
    }
   ],
   "source": [
    "%%file sgemm_texture_object.cu\n",
    "\n",
    "#include \"sgemm.cuh\"\n",
    "\n",
    "__global__ void sgemm_texture_object(cudaTextureObject_t tex_A, cudaTextureObject_t tex_B, Matrix C, \n",
    "                      const float alpha, const float beta, \n",
    "                      const int width, const int height) {\n",
    "    int idx_x = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "    int idx_y = blockDim.y * blockIdx.y + threadIdx.y;\n",
    "    int idx = idx_y * width + idx_x;\n",
    "    \n",
    "    if (idx_x >= width || idx_y >= height)\n",
    "        return;\n",
    "    \n",
    "    float value = 0.f;\n",
    "    for (int e = 0; e < width; e++)\n",
    "        value = alpha * tex1Dfetch<float>(tex_A, idx_y * width + e) * tex1Dfetch<float>(tex_B, e * width + idx_x);\n",
    "    C.elements[idx] = value + beta * C.elements[idx];\n",
    "}\n",
    "\n",
    "void launch_sgemm_texture_object(Matrix &dA, Matrix &dB, Matrix &dC,\n",
    "                      const float alpha, const float beta, \n",
    "                      const int width, const int height) {    \n",
    "    // create texture object\n",
    "    cudaResourceDesc resDesc_A, resDesc_B;\n",
    "    memset(&resDesc_A, 0, sizeof(resDesc_A));\n",
    "    resDesc_A.resType = cudaResourceTypeLinear;\n",
    "    resDesc_A.res.linear.devPtr = dA.elements;\n",
    "    resDesc_A.res.linear.desc.f = cudaChannelFormatKindFloat;\n",
    "    resDesc_A.res.linear.desc.x = 32; // bits per channel\n",
    "    resDesc_A.res.linear.sizeInBytes = width * height * sizeof(float);\n",
    "    \n",
    "    memcpy(&resDesc_B, &resDesc_A, sizeof(resDesc_A));\n",
    "    resDesc_B.res.linear.devPtr = dB.elements;\n",
    "\n",
    "    cudaTextureDesc texDesc;\n",
    "    memset(&texDesc, 0, sizeof(texDesc));\n",
    "    texDesc.readMode = cudaReadModeElementType;\n",
    "\n",
    "    // create texture object: we only have to do this once!\n",
    "    cudaTextureObject_t tex_A, tex_B;\n",
    "    cudaCreateTextureObject(&tex_A, &resDesc_A, &texDesc, NULL);\n",
    "    cudaCreateTextureObject(&tex_B, &resDesc_B, &texDesc, NULL);\n",
    "    \n",
    "    dim3 blockDim(16, 16);\n",
    "    dim3 gridDim((width + blockDim.x - 1) / blockDim.x, (height + blockDim.y - 1) / blockDim.y);\n",
    "    sgemm_texture_object<<<gridDim, blockDim>>>(tex_B, tex_B, dC, alpha, beta, width, height);\n",
    "    \n",
    "    cudaDestroyTextureObject(tex_A);\n",
    "    cudaDestroyTextureObject(tex_B);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 빌드 및 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc --ptxas-options=--verbose -gencode=arch=compute_35,code=sm_35 -I/usr/local/cuda/samples/common/inc test_texture.cu -c test_texture.o\n",
      "ptxas info    : 0 bytes gmem\n",
      "ptxas info    : Compiling entry function '_Z13sgemm_texture6MatrixS_S_ffii' for 'sm_35'\n",
      "ptxas info    : Function properties for _Z13sgemm_texture6MatrixS_S_ffii\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 8 registers, 392 bytes cmem[0], 2 textures\n",
      "ptxas info    : Compiling entry function '_Z5sgemm6MatrixS_S_ffii' for 'sm_35'\n",
      "ptxas info    : Function properties for _Z5sgemm6MatrixS_S_ffii\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 13 registers, 384 bytes cmem[0]\n",
      "ptxas info    : Compiling entry function '_Z20sgemm_texture_objectyy6Matrixffii' for 'sm_35'\n",
      "ptxas info    : Function properties for _Z20sgemm_texture_objectyy6Matrixffii\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 8 registers, 368 bytes cmem[0]\n",
      "nvcc --ptxas-options=--verbose -gencode=arch=compute_35,code=sm_35 -I/usr/local/cuda/samples/common/inc test_texture.o -o test_texture\n"
     ]
    }
   ],
   "source": [
    "! make test_texture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "texture referecne mode...\n",
      "SGEMM CUDA Elapsed time (original): 24.311520 ms\n",
      "SGEMM CUDA Elapsed time (texture): 65.727905 ms\n",
      "Host time: 99.762920 ms\n",
      "Success !!\n"
     ]
    }
   ],
   "source": [
    "! ./test_texture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "texture object mode...\n",
      "SGEMM CUDA Elapsed time (original): 193.555389 ms\n",
      "SGEMM CUDA Elapsed time (texture): 516.679016 ms\n",
      "Host time: 748.431495 ms\n",
      "Success !!\n"
     ]
    }
   ],
   "source": [
    "! ./test_texture 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실행결과 오히려 속도가 저하되었습니다.\n",
    "\n",
    "사실 이 예제에서는 texutre memory의 장점인 interpolation 등을 활용하지 않았기에, Texture memory를 활용하기 위한 overhead만이 측정된 예제라고 할 수 있습니다. 경우에 따라서 texture memory의 특성에 맞는 application이라면 그래도 시도해볼만한 메모리입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_texture.cu\n"
     ]
    }
   ],
   "source": [
    "%%file test_texture.cu\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <time.h>\n",
    "#include \"sgemm.cuh\"\n",
    "#include \"sgemm.cu\"\n",
    "#include \"sgemm_texture_reference.cu\"\n",
    "#include \"sgemm_texture_object.cu\"\n",
    "\n",
    "void InitMatrix(Matrix &mat, const int width, const int height, TARGET target = HOST, MEMTYPE memtype = NORMAL);\n",
    "bool IsMatDiff(Matrix &A, Matrix &B);\n",
    "\n",
    "int main(int argc, char* argv[]) {\n",
    "    Matrix A, B, C, D;\n",
    "    Matrix dA, dB, dC, dD;\n",
    "    const float alpha = 2.f;\n",
    "    const float beta = .5f;\n",
    "    const int width = 2048;\n",
    "    const int height = width;\n",
    "    float elapsed_gpu;\n",
    "    double elapsed_cpu;\n",
    "    \n",
    "    // Select Host memory type (NORMAL, PINNED)\n",
    "    MEMTYPE memtype = PINNED;\n",
    "    bool texture_reference_mode = true;\n",
    "    if (argc > 1) {\n",
    "        if (argv[1]) {\n",
    "            texture_reference_mode = false;\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    // CUDA Event Create to estimate elased time\n",
    "    cudaEvent_t start_org, stop_org, start_opt, stop_opt;\n",
    "    struct timespec begin, finish;\n",
    "    \n",
    "    cudaEventCreate(&start_org);\n",
    "    cudaEventCreate(&stop_org);\n",
    "    cudaEventCreate(&start_opt);\n",
    "    cudaEventCreate(&stop_opt);\n",
    "    \n",
    "    // Initialize host matrix\n",
    "    InitMatrix(A, width, height, HOST, memtype);\n",
    "    InitMatrix(B, width, height, HOST, memtype);\n",
    "    InitMatrix(C, width, height, HOST, memtype);\n",
    "    InitMatrix(D, width, height, HOST, memtype);\n",
    "\n",
    "    // CUDA Memory Initialize\n",
    "    InitMatrix(dA, width, height, DEVICE);\n",
    "    InitMatrix(dB, width, height, DEVICE);\n",
    "    InitMatrix(dC, width, height, DEVICE);\n",
    "    InitMatrix(dD, width, height, DEVICE);\n",
    "    \n",
    "    // CUDA Operation\n",
    "    clock_gettime(CLOCK_MONOTONIC, &begin);\n",
    "    \n",
    "    // Copy host data to the device (CUDA global memory)\n",
    "    cudaMemcpyAsync(dA.elements, A.elements, width * height * sizeof(float), cudaMemcpyHostToDevice);\n",
    "    cudaMemcpyAsync(dB.elements, B.elements, width * height * sizeof(float), cudaMemcpyHostToDevice);\n",
    "    cudaMemcpyAsync(dC.elements, C.elements, width * height * sizeof(float), cudaMemcpyHostToDevice);\n",
    "    cudaMemcpyAsync(dD.elements, D.elements, width * height * sizeof(float), cudaMemcpyHostToDevice);\n",
    "    \n",
    "    // Launch GPU Kernel\n",
    "    cudaEventRecord(start_org, 0);\n",
    "    launch_sgemm(dA, dB, dC, alpha, beta, width, height);\n",
    "    cudaEventRecord(stop_org, 0);\n",
    "    cudaEventRecord(start_opt, 0);\n",
    "    if (texture_reference_mode == true) {\n",
    "        printf(\"texture referecne mode...\\n\");\n",
    "        launch_sgemm_texture(dA, dB, dD, alpha, beta, width, height);\n",
    "    } else {\n",
    "        printf(\"texture object mode...\\n\");\n",
    "        launch_sgemm_texture_object(dA, dB, dD, alpha, beta, width, height);\n",
    "    }\n",
    "    cudaEventRecord(stop_opt, 0);\n",
    "    \n",
    "    // Copy computation result from the Device the host memory\n",
    "    cudaMemcpyAsync(C.elements, dC.elements, width * height * sizeof(float), cudaMemcpyDeviceToHost);\n",
    "    cudaMemcpyAsync(D.elements, dD.elements, width * height * sizeof(float), cudaMemcpyDeviceToHost);\n",
    "    \n",
    "    // Estimate CUDA operation time\n",
    "    cudaEventSynchronize(stop_org);\n",
    "    cudaEventSynchronize(stop_opt);\n",
    "    cudaDeviceSynchronize();\n",
    "    clock_gettime(CLOCK_MONOTONIC, &finish);\n",
    "    \n",
    "    cudaEventElapsedTime(&elapsed_gpu, start_org, stop_org);\n",
    "    printf(\"SGEMM CUDA Elapsed time (original): %f ms\\n\", elapsed_gpu);\n",
    "    cudaEventElapsedTime(&elapsed_gpu, start_opt, stop_opt);\n",
    "    printf(\"SGEMM CUDA Elapsed time (texture): %f ms\\n\", elapsed_gpu);\n",
    "    elapsed_cpu = (finish.tv_sec - begin.tv_sec);\n",
    "    elapsed_cpu += (finish.tv_nsec - begin.tv_nsec) / 1000000000.0;\n",
    "    printf(\"Host time: %f ms\\n\", elapsed_cpu * 1000);\n",
    "    \n",
    "    if (IsMatDiff(C, D)) {\n",
    "        printf(\"Something wrong!!\\n\");\n",
    "    }\n",
    "    else {\n",
    "        printf(\"Success !!\\n\");\n",
    "    }\n",
    "    \n",
    "    // finalize CUDA event\n",
    "    cudaEventDestroy(start_org);\n",
    "    cudaEventDestroy(stop_org);\n",
    "    cudaEventDestroy(start_opt);\n",
    "    cudaEventDestroy(stop_opt);\n",
    "    \n",
    "    // Finalize\n",
    "    cudaFree(dA.elements);\n",
    "    cudaFree(dB.elements);\n",
    "    cudaFree(dC.elements);\n",
    "    cudaFree(dD.elements);\n",
    "    \n",
    "    if (memtype == NORMAL) {\n",
    "        free(A.elements);\n",
    "        free(B.elements);\n",
    "        free(C.elements);\n",
    "        free(D.elements);\n",
    "    }\n",
    "    else {\n",
    "        cudaFreeHost(A.elements);\n",
    "        cudaFreeHost(B.elements);\n",
    "        cudaFreeHost(C.elements);\n",
    "        cudaFreeHost(D.elements);\n",
    "    }\n",
    "    \n",
    "    return 0;\n",
    "}\n",
    "\n",
    "void InitMatrix(Matrix &mat, const int width, const int height, TARGET target, MEMTYPE memtype) {\n",
    "    mat.width = width;\n",
    "    mat.height = height;\n",
    "    \n",
    "    if (target == DEVICE) {\n",
    "        cudaMalloc((void**)&mat.elements, width * height * sizeof(float));\n",
    "    }\n",
    "    else {\n",
    "        if (memtype == NORMAL)\n",
    "            mat.elements = (float*)malloc(width * height * sizeof(float));\n",
    "        else\n",
    "            cudaHostAlloc(&mat.elements, width * height * sizeof(float), cudaHostAllocDefault);\n",
    "    \n",
    "        for (int row = 0; row < height; row++) {\n",
    "            for (int col = 0; col < width; col++) {\n",
    "                mat.elements[row * width + col] = row * width + col * 0.001;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "bool IsMatDiff(Matrix &A, Matrix &B) {\n",
    "    if (A.width != B.width || A.height != B.height) {\n",
    "        return true;\n",
    "    }\n",
    "    \n",
    "    int count = 0;\n",
    "    for (int row = 0; row < A.height; row++) {\n",
    "        for (int col = 0; col < A.width; col++) {\n",
    "            count += (A.elements[row * A.width + col] != B.elements[row * B.width + col]) ? 1 : 0;\n",
    "            \n",
    "            if (A.elements[row * A.width + col] != B.elements[row * B.width + col]) {\n",
    "            printf(\"%f %f\\n\", A.elements[row * A.width + col], B.elements[row * B.width + col]);\n",
    "            break;\n",
    "        }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    if (count != 0) {\n",
    "        printf(\"Count: %d\\n\", count);\n",
    "        return true;\n",
    "    }\n",
    "    return false;\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
