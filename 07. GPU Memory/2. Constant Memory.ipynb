{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Constant Memory\n",
    "\n",
    "\n",
    "Constant Memory는 Read-only Cache 메모리입니다. 64KB 밖에 되지는 않지만 CUDA block간에 모두 공유가 되어서 쉽게 이용할 수 있습니다.\n",
    "\n",
    "다만 이번 예제에서는 SGEMM이 아닌 다른 예제를 활용해서 속도를 비교하도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting constant.cu\n"
     ]
    }
   ],
   "source": [
    "%%file constant.cu\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <math_constants.h>\n",
    "\n",
    "#define BLOCK_DIM 16\n",
    "#define PI_STEP 256\n",
    "\n",
    "__constant__ float c_sin_table[PI_STEP * 2];\n",
    "__constant__ float c_cos_table[PI_STEP * 2];\n",
    "\n",
    "__global__ void foo(float* out, const int width, const int height) {\n",
    "    int idx_x = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "    int idx_y = blockDim.y * blockIdx.y + threadIdx.y;\n",
    "    int idx = idx_y * width + idx_x;\n",
    "    \n",
    "    if (idx_x < width && idx_y < height) {\n",
    "        \n",
    "        out[idx] = sin(idx * CUDART_PI_F / PI_STEP) * sin(idx * CUDART_PI_F / PI_STEP)\n",
    "                 - cos(idx * CUDART_PI_F / PI_STEP) * cos(idx * CUDART_PI_F / PI_STEP);\n",
    "    }\n",
    "}\n",
    "\n",
    "__global__ void fooConstant(float* out, const int width, const int height) {\n",
    "    int idx_x = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "    int idx_y = blockDim.y * blockIdx.y + threadIdx.y;\n",
    "    int idx = idx_y * width + idx_x;\n",
    "    \n",
    "    if (idx_x < width && idx_y < height) {\n",
    "        out[idx] = c_sin_table[idx % (PI_STEP * 2)] * c_sin_table[idx % (PI_STEP * 2)]\n",
    "                 - c_cos_table[idx % (PI_STEP * 2)] * c_cos_table[idx % (PI_STEP * 2)];\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int width = 4096;\n",
    "    int height = 4096;\n",
    "    float sin_table[PI_STEP * 2];\n",
    "    float cos_table[PI_STEP * 2];\n",
    "    float *first, *second;\n",
    "    float *d_first, *d_second;\n",
    "    \n",
    "    // CUDA Event Create to estimate elased time\n",
    "    cudaEvent_t start, stop;\n",
    "    float elapsed_gpu;\n",
    "    \n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    \n",
    "    for (int i = 0; i < PI_STEP * 2; i++) {\n",
    "        sin_table[i] = sin(i * CUDART_PI_F / PI_STEP);\n",
    "        cos_table[i] = cos(i * CUDART_PI_F / PI_STEP);\n",
    "    }\n",
    "    \n",
    "    first = (float*)malloc(width * height * sizeof(float));\n",
    "    second = (float*)malloc(width * height * sizeof(float));\n",
    "    cudaMalloc((void**)&d_first, width * height * sizeof(float));\n",
    "    cudaMalloc((void**)&d_second, width * height * sizeof(float));\n",
    "    \n",
    "    // Copy to Constant Memory\n",
    "    cudaMemcpyToSymbol(c_sin_table, sin_table, PI_STEP * 2 * sizeof(float));\n",
    "    cudaMemcpyToSymbol(c_cos_table, cos_table, PI_STEP * 2 * sizeof(float));\n",
    "    \n",
    "    dim3 blockDim(BLOCK_DIM, BLOCK_DIM);\n",
    "    dim3 gridDim((width + BLOCK_DIM - 1) / BLOCK_DIM, (height + BLOCK_DIM - 1) / BLOCK_DIM);\n",
    "    \n",
    "    cudaEventRecord(start, 0);\n",
    "    foo<<<gridDim, blockDim>>>(d_first, width, height);\n",
    "    \n",
    "    // Estimate CUDA operation time\n",
    "    cudaEventRecord(stop, 0);\n",
    "    cudaEventSynchronize(stop);\n",
    "    \n",
    "    cudaEventElapsedTime(&elapsed_gpu, start, stop);\n",
    "    printf(\"SGEMM CUDA Elapsed time (operation): %f ms\\n\", elapsed_gpu);\n",
    "        \n",
    "    cudaEventRecord(start, 0);\n",
    "    fooConstant<<<gridDim, blockDim>>>(d_second, width, height);\n",
    "    \n",
    "    // Estimate CUDA operation time\n",
    "    cudaEventRecord(stop, 0);\n",
    "    cudaEventSynchronize(stop);\n",
    "    \n",
    "    cudaEventElapsedTime(&elapsed_gpu, start, stop);\n",
    "    printf(\"SGEMM CUDA Elapsed time (constant): %f ms\\n\", elapsed_gpu);\n",
    "    \n",
    "    cudaMemcpy(first, d_first, width * height * sizeof(float), cudaMemcpyDeviceToHost);\n",
    "    cudaMemcpy(second, d_second, width * height * sizeof(float), cudaMemcpyDeviceToHost);\n",
    "    \n",
    "    float diff_sum = 0.f;\n",
    "    for (int i = 0; i < width * height; i++) {\n",
    "        if (first[i] - second[i] != 0.f) {\n",
    "            diff_sum += first[i] - second[i];\n",
    "        }\n",
    "    }\n",
    "    printf(\"diff_sum: %f\\n\", diff_sum);\n",
    "    \n",
    "    cudaFree(d_first);\n",
    "    cudaFree(d_second);\n",
    "    free(first);\n",
    "    free(second);\n",
    "    \n",
    "    // finalize CUDA event\n",
    "    cudaEventDestroy(start);\n",
    "    cudaEventDestroy(stop);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc --ptxas-options=--verbose -gencode arch=compute_30,code=sm_30 -I/usr/local/cuda/samples/common/inc constant.cu -o constant \n",
      "ptxas info    : 0 bytes gmem, 4120 bytes cmem[3]\n",
      "ptxas info    : Compiling entry function '_Z11fooConstantPfii' for 'sm_30'\n",
      "ptxas info    : Function properties for _Z11fooConstantPfii\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 8 registers, 336 bytes cmem[0]\n",
      "ptxas info    : Compiling entry function '_Z3fooPfii' for 'sm_30'\n",
      "ptxas info    : Function properties for _Z3fooPfii\n",
      "    32 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 14 registers, 336 bytes cmem[0], 48 bytes cmem[2]\n"
     ]
    }
   ],
   "source": [
    "! make constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGEMM CUDA Elapsed time (operation): 15.945632 ms\n",
      "SGEMM CUDA Elapsed time (constant): 9.857184 ms\n",
      "diff_sum: -0.066286\n"
     ]
    }
   ],
   "source": [
    "! ./constant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 예제를 통해서 Constant Memory를 사용할 경우, 사용하지 않은 경우에 비해서 성능 향상을 얻을 수 있었습니다.\n",
    "\n",
    "위 예제의 경우처럼, constant memory는 look-up table을 구성해서 사용하는데 이점이 있습니다. 하지만 look-up table을 이용했을 때 단점인 연산오차에 대해 감안하셔야 합니다. 개발하시는 application의 오차 허용 범위가 look-up table을 사용한 경우와, look-up table이 이미 있고 Constant memory의 크기보다 작은 경우 사용해 보실 것을 권해 드립니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
