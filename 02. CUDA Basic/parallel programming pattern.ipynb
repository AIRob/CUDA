{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Communication Pattern for CUDA I\n",
    "\n",
    "* Map\n",
    "* Gather\n",
    "* Stencil\n",
    "* Scatter\n",
    "* Transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%file util.c\n",
    "\n",
    "float* get_buffer(int n_size) {\n",
    "    float* buffer = (float*)malloc(n_size * sizeof(float));\n",
    "    \n",
    "    time_t t;\n",
    "    srand((unsigned) time(&t));\n",
    "    \n",
    "    for (int i = 0; i < n_size; i++) {\n",
    "        //buffer[i] = (float)rand()/(float)(RAND_MAX/100);\n",
    "        buffer[i] = i;\n",
    "    }\n",
    "    return buffer;\n",
    "}\n",
    "\n",
    "void check_result(float *p_A, float *p_B, int n_size) {\n",
    "    int compare = 0;\n",
    "    for (int i = 0; i < n_size; i++) {\n",
    "        compare += (p_A[i] != p_B[i]) ? 1 : 0;\n",
    "    }\n",
    "    printf(\"Result: %d\\n\", compare);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%file map.cu\n",
    "\n",
    "#include <stdio.h>\n",
    "#include \"util.c\"\n",
    "\n",
    "__global__\n",
    "void d_map(float* d_out, float* d_in, int n_size) {\n",
    "    int idx = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "    \n",
    "    d_out[idx] = d_in[idx];\n",
    "}\n",
    "\n",
    "__global__\n",
    "void d_map_reverse(float* d_out, float* d_in, int n_size) {\n",
    "    int idx = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "    \n",
    "    d_out[n_size - idx] = d_in[idx];\n",
    "}\n",
    "\n",
    "void reverse(float* p_out, float* p_in, int n_size) {\n",
    "    for (int i = 0; i < n_size; i++) {\n",
    "        p_out[n_size - i] = p_in[i];\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    float *p_in, *p_out, *p_reverse;\n",
    "    float *d_in, *d_out;\n",
    "    \n",
    "    int n_size = 65536;\n",
    "    \n",
    "    p_in = get_buffer(n_size);\n",
    "    p_out = get_buffer(n_size);\n",
    "    p_reverse = get_buffer(n_size);\n",
    "    \n",
    "    cudaMalloc((void**)&d_in, n_size * sizeof(float));\n",
    "    cudaMalloc((void**)&d_out, n_size * sizeof(float));\n",
    "    \n",
    "    cudaMemcpy(d_in, p_in, n_size * sizeof(float), cudaMemcpyHostToDevice);\n",
    "    \n",
    "    dim3 blockDim(256);\n",
    "    dim3 gridDim((n_size + blockDim.x - 1) / blockDim.x);\n",
    "    d_map<<<gridDim, blockDim>>>(d_out, d_in, n_size);\n",
    "    \n",
    "    cudaMemcpy(p_out, d_out, n_size * sizeof(float), cudaMemcpyDeviceToHost);\n",
    "    \n",
    "    check_result(p_in, p_out, n_size);\n",
    "    \n",
    "    d_map_reverse<<<gridDim, blockDim>>>(d_out, d_in, n_size);\n",
    "    cudaMemcpy(p_out, d_out, n_size * sizeof(float), cudaMemcpyDeviceToHost);\n",
    "    \n",
    "    reverse(p_reverse, p_in, n_size);\n",
    "    check_result(p_reverse, p_out, n_size);\n",
    "    \n",
    "    cudaFree(d_in);\n",
    "    cudaFree(d_out);\n",
    "    \n",
    "    free(p_in);\n",
    "    free(p_out);\n",
    "    free(p_reverse);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! make map && ./map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%file gather.cu\n",
    "#include <stdio.h>\n",
    "#include \"util.c\"\n",
    "\n",
    "const int n_width = 1024;\n",
    "const int n_height = 1024;\n",
    "\n",
    "void gather_sum(float* p_out, float* p_in, int n_filter_size, int n_width, int n_height) {\n",
    "    for (int row = 0; row < n_height; row++) {\n",
    "        for (int col = 0; col < n_width; col++) {\n",
    "            float sum = 0.f;\n",
    "            \n",
    "            for (int row_filter = 0; row_filter < n_filter_size; row_filter++) {\n",
    "                for (int col_filter = 0; col_filter < n_filter_size; col_filter++) {\n",
    "                    int input_idx = n_width * (row + row_filter) + col + col_filter;\n",
    "                    \n",
    "                    if ((row + row_filter >= 0 && row + row_filter < n_height) && \n",
    "                        (col + col_filter >= 0 && col + col_filter < n_width)) {\n",
    "                        sum += p_in[input_idx];\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            p_out[row * n_width + col] = sum;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "__global__\n",
    "void d_gather_sum(float* p_out, float* p_in, int n_filter_size, int n_width, int n_height) {\n",
    "    // TODO: Write gather code\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    float *p_in, *p_out, *p_out_host;\n",
    "    float *d_in, *d_out;\n",
    "    int n_filter_size = 3;\n",
    "    int n_size = n_width * n_height;\n",
    "    \n",
    "    p_in = get_buffer(n_size);\n",
    "    p_out = get_buffer(n_size);\n",
    "    p_out_host = get_buffer(n_size);\n",
    "    \n",
    "    cudaMalloc((void**)&d_in, n_size * sizeof(float));\n",
    "    cudaMalloc((void**)&d_out, n_size * sizeof(float));\n",
    "  \n",
    "    cudaMemcpy(d_in, p_in, n_size * sizeof(float), cudaMemcpyHostToDevice);\n",
    "    \n",
    "    gather_sum(p_out_host, p_in, n_filter_size, n_width, n_height);\n",
    "    \n",
    "    dim3 blockDim(16, 16);\n",
    "    dim3 gridDim((n_width + blockDim.x - 1) / blockDim.x, (n_height + blockDim.y - 1) / blockDim.y);\n",
    "    d_gather_sum<<<gridDim, blockDim>>>(d_out, d_in, n_filter_size, n_width, n_height);\n",
    "    \n",
    "    cudaMemcpy(p_out, d_out, n_size * sizeof(float), cudaMemcpyDeviceToHost);\n",
    "    \n",
    "    check_result(p_out, p_out_host, n_size);\n",
    "    printf(\"%d\\n\", n_size);\n",
    "    \n",
    "    cudaFree(d_in);\n",
    "    cudaFree(d_out);\n",
    "    \n",
    "    free(p_in);\n",
    "    free(p_out);\n",
    "    free(p_out_host);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! make gather && ./gather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Stencil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%file stencil.cu\n",
    "#include <stdio.h>\n",
    "#include \"util.c\"\n",
    "\n",
    "const int n_width = 1024;\n",
    "const int n_height = 1024;\n",
    "\n",
    "void stencil_sum(float* p_out, float* p_in, int* p_filter, int n_filter_size, int n_width, int n_height) {\n",
    "    for (int row = 0; row < n_height; row++) {\n",
    "        for (int col = 0; col < n_width; col++) {\n",
    "            float sum = 0.f;\n",
    "            for (int i = 0; i < n_filter_size; i++) {\n",
    "                int col_filter = p_filter[i*2 + 0];\n",
    "                int row_filter = p_filter[i*2 + 1];\n",
    "                col_filter = 0;\n",
    "                row_filter = 1;\n",
    "                int input_idx = n_width * (row + row_filter) + col + col_filter;\n",
    "                    \n",
    "                if ((row + row_filter >= 0 && row + row_filter < n_height) && \n",
    "                    (col + col_filter >= 0 && col + col_filter < n_width)) {\n",
    "                    sum += p_in[input_idx];\n",
    "                }\n",
    "            }\n",
    "            p_out[row * n_width + col] = sum;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "__global__\n",
    "void d_stencil_sum(float* p_out, float* p_in, int* p_filter, int n_filter_size, int n_width, int n_height) {\n",
    "    // TODO: Write stencil code\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    float *p_in, *p_out, *p_out_host;\n",
    "    float *d_in, *d_out;\n",
    "    int *p_filter, *d_filter;\n",
    "    int n_filter_size = 5;\n",
    "    int n_size = n_width * n_height;\n",
    "    int stencil_filter[5][2] = {{0, -1}, {-1, 0}, {0, 0}, {1, 0}, {0, 1}};\n",
    "    \n",
    "    p_in = get_buffer(n_size);\n",
    "    p_out = get_buffer(n_size);\n",
    "    p_out_host = get_buffer(n_size);\n",
    "    p_filter = (int*)get_buffer(n_filter_size * 2);\n",
    "    \n",
    "    // Build stencil filter\n",
    "    memcpy(p_filter, stencil_filter, n_filter_size * 2 * sizeof(int));\n",
    "        \n",
    "    cudaMalloc((void**)&d_in, n_size * sizeof(float));\n",
    "    cudaMalloc((void**)&d_out, n_size * sizeof(float));\n",
    "    cudaMalloc((void**)&d_filter, n_filter_size * 2 * sizeof(int));\n",
    "  \n",
    "    cudaMemcpy(d_in, p_in, n_size * sizeof(float), cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_filter, p_filter, n_filter_size * 2 * sizeof(float), cudaMemcpyHostToDevice);\n",
    "    \n",
    "    stencil_sum(p_out_host, p_in, p_filter, n_filter_size, n_width, n_height);\n",
    "    \n",
    "    // TODO: Write Kernel Call line\n",
    "    \n",
    "    cudaMemcpy(p_out, d_out, n_size * sizeof(float), cudaMemcpyDeviceToHost);\n",
    "    \n",
    "    check_result(p_out_host, p_out, n_size);\n",
    "        \n",
    "    cudaFree(d_in);\n",
    "    cudaFree(d_out);\n",
    "    cudaFree(d_filter);\n",
    "    \n",
    "    free(p_in);\n",
    "    free(p_out);\n",
    "    free(p_out_host);\n",
    "    free(p_filter);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! make stencil && ./stencil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%file scatter.cu\n",
    "#include <stdio.h>\n",
    "#include \"util.c\"\n",
    "\n",
    "const int n_width = 1024;\n",
    "const int n_height = 1024;\n",
    "\n",
    "void scatter(float* p_out, float* p_in, int n_width, int n_height) {\n",
    "    for (int j = 0; j < n_width; j++) {\n",
    "        for (int i = 0; i < n_height; i++) {\n",
    "            p_out[i * n_width + j] = j;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "__global__\n",
    "void d_scatter_1D(float* d_out, float* d_in, int n_width, int n_height) {\n",
    "    // TODO: Write scatter code\n",
    "}\n",
    "\n",
    "void CallScatter1D(float* d_out, float* d_in, int n_width, int n_height) {\n",
    "    // TODO: Write Kernal Call using 1D block size\n",
    "    dim3 blockDim(256);\n",
    "}\n",
    "\n",
    "__global__\n",
    "void d_scatter_2D(float* d_out, float* d_in, int n_width, int n_height) {\n",
    "    // TODO: Write scatter code\n",
    "}\n",
    "\n",
    "void CallScatter2D(float* d_out, float* d_in, int n_width, int n_height) {\n",
    "    // TODO: Write Kernel Call using 2D block size\n",
    "    dim3 blockDim(16, 16);\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    float *p_in, *p_out, *p_out_host;\n",
    "    float *d_in, *d_out;\n",
    "    \n",
    "    p_in = get_buffer(n_width);\n",
    "    p_out = get_buffer(n_width * n_height);\n",
    "    p_out_host = get_buffer(n_width * n_height);\n",
    "    \n",
    "    cudaMalloc((void**)&d_in, n_width * sizeof(float));\n",
    "    cudaMalloc((void**)&d_out, n_width * n_height * sizeof(float));\n",
    "    \n",
    "    cudaMemcpy(d_in, p_in, n_width * sizeof(float), cudaMemcpyHostToDevice);\n",
    "    \n",
    "    scatter(p_out_host, p_in, n_width, n_height);\n",
    "    \n",
    "    CallScatter1D(d_out, d_in, n_width, n_height);\n",
    "    cudaMemcpy(p_out, d_out, n_width * n_height * sizeof(float), cudaMemcpyDeviceToHost);\n",
    "    check_result(p_out_host, p_out, n_width * n_height);\n",
    "    \n",
    "    CallScatter2D(d_out, d_in, n_width, n_height);\n",
    "    cudaMemcpy(p_out, d_out, n_width * n_height * sizeof(float), cudaMemcpyDeviceToHost);\n",
    "    check_result(p_out_host, p_out, n_width * n_height);\n",
    "    \n",
    "    cudaFree(d_in);\n",
    "    cudaFree(d_out);\n",
    "    \n",
    "    free(p_in);\n",
    "    free(p_out);\n",
    "    free(p_out_host);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! make scatter && ./scatter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%file transpose.cu\n",
    "#include <stdio.h>\n",
    "#include \"util.c\"\n",
    "\n",
    "void transpose(float *p_out, float *p_in, int n_width, int n_height) {\n",
    "    for (int j = 0; j < n_height; j++) {\n",
    "        for (int i = 0; i < n_width; i++) {\n",
    "            p_out[i * n_height + j] = p_in[j * n_width + i];\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "__global__ \n",
    "void d_transpose(float *d_out, float *d_in, int n_width, int n_height) {\n",
    "    // TODO: Write transpose code\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    float *p_in, *p_out, *p_out_cuda;\n",
    "    float *d_in, *d_out;\n",
    "    \n",
    "    int n_width = 1920;\n",
    "    int n_height = 1080;\n",
    "    \n",
    "    p_in = get_buffer(n_width * n_height);\n",
    "    p_out = get_buffer(n_width * n_height);\n",
    "    p_out_cuda = get_buffer(n_width * n_height);\n",
    "    \n",
    "    // Step 1. Allocate to GPU memory\n",
    "    cudaMalloc((void**)&d_in, n_width * n_height * sizeof(float));\n",
    "    cudaMalloc((void**)&d_out, n_width * n_height * sizeof(float));\n",
    "    \n",
    "    // Initialize input data\n",
    "    for (int j = 0; j < n_height; j++) {\n",
    "        for (int i = 0; i < n_width; i++) {\n",
    "            p_in[j * n_width + i] = float(j * n_width + i);\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    // Step 2. Copy to GPU memory\n",
    "    cudaMemcpy(d_in, p_in, n_width * n_height * sizeof(float), cudaMemcpyHostToDevice);\n",
    "    \n",
    "    transpose(p_out, p_in, n_width, n_height);\n",
    "    \n",
    "    // Step 3. Kernel leaunch\n",
    "    dim3 blockDim(16, 16);\n",
    "    dim3 gridDim((n_width + blockDim.x - 1) / blockDim.x, (n_height + blockDim.y - 1) / blockDim.y);\n",
    "    d_transpose<<<gridDim, blockDim>>>(d_out, d_in, n_width, n_height);\n",
    "    \n",
    "    // Step 4. Copy from GPU\n",
    "    cudaMemcpy(p_out_cuda, d_out, n_width * n_height * sizeof(float), cudaMemcpyDeviceToHost);\n",
    "    \n",
    "    // Step 5. check result\n",
    "    check_result(p_out, p_out_cuda, n_width * n_height);\n",
    "    \n",
    "    // Step 6. free GPU memory\n",
    "    cudaFree(d_in);\n",
    "    cudaFree(d_out);\n",
    "    \n",
    "    free(p_in);\n",
    "    free(p_out);\n",
    "    free(p_out_cuda);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! make transpose && ./transpose"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
