{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 처음 해보는 CUDA Programming\n",
    "\n",
    "가볍게 배열을 복사하는 프로그램을 짜봅시다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copying an array in C\n",
    "\n",
    "메모리에 있는 데이터를 복사할 때 우리는 보통 API를 이용해서 처리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%file vector_copy.cc\n",
    "#include <stdio.h>\n",
    "#include <string.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "#define BUF_SIZE 256\n",
    "\n",
    "int main() {\n",
    "    float* p_x = (float*)malloc(BUF_SIZE * sizeof(float));\n",
    "    float* p_y = (float*)malloc(BUF_SIZE * sizeof(float));\n",
    "    \n",
    "    for (int i = 0; i < BUF_SIZE; i++) {\n",
    "        p_x[i] = i * 1.5f;\n",
    "    }\n",
    "\n",
    "    // Write vector copy code\n",
    "    memcpy(p_y, p_x, BUF_SIZE * sizeof(float));\n",
    "    \n",
    "    float sum = 0.f;\n",
    "    for (int i = 0; i < BUF_SIZE; i++) {\n",
    "        sum += p_y[i] - p_x[i];\n",
    "    }\n",
    "    printf(\"Diff. Sum: %f\", sum);\n",
    "    \n",
    "    free(p_x);\n",
    "    free(p_y);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!make vector_copy && ./vector_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing Iterative Copying Code\n",
    "\n",
    "위에서 사용한 memcpy는 사실 내부적으로는 순차적으로 복사하는 과정을 거치게 됩니다.\n",
    "\n",
    "memcpy 명령을 그대로 둔 상태로 복사를 해 보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%file buffer_copy_iter.cc\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "#define BUF_SIZE 256\n",
    "\n",
    "void memcpy(float *out, float *in, size_t length) {\n",
    "    for (int i = 0; i < length / (int)sizeof(float); i++) {\n",
    "        out[i] = in[i];\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    float* p_x = (float*)malloc(BUF_SIZE * sizeof(float));\n",
    "    float* p_y = (float*)malloc(BUF_SIZE * sizeof(float));\n",
    "    \n",
    "    for (int i = 0; i < BUF_SIZE; i++) {\n",
    "        p_x[i] = i * 1.5f;\n",
    "    }\n",
    "\n",
    "    // Write vector copy code\n",
    "    memcpy(p_y, p_x, BUF_SIZE * sizeof(float));\n",
    "    \n",
    "    float sum = 0.f;\n",
    "    for (int i = 0; i < BUF_SIZE; i++) {\n",
    "        sum += p_y[i] - p_x[i];\n",
    "    }\n",
    "    printf(\"Diff. Sum: %f\", sum);\n",
    "    \n",
    "    free(p_x);\n",
    "    free(p_y);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!make buffer_copy_iter && ./buffer_copy_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA Buffer Allocation\n",
    "\n",
    "이제 CUDA 코드 작성을 시작해 보도록 하겠습니다. 먼저 시작할 내용은 GPU에서 사용할 메모리를 할당하고 해제하는 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%file buffer_alloc.cc\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "#define BUF_SIZE 256\n",
    "\n",
    "void memcpy(float *out, float *in, size_t length) {\n",
    "    for (int i = 0; i < length / (int)sizeof(float); i++) {\n",
    "        out[i] = in[i];\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    float* p_x = (float*)malloc(BUF_SIZE * sizeof(float));\n",
    "    float* p_y = (float*)malloc(BUF_SIZE * sizeof(float));\n",
    "    \n",
    "    // Step 1. CUDA Buffer allocation\n",
    "    cudaMalloc()\n",
    "    \n",
    "    for (int i = 0; i < BUF_SIZE; i++) {\n",
    "        p_x[i] = i * 1.5f;\n",
    "    }\n",
    "\n",
    "    // Write vector copy code\n",
    "    memcpy(p_y, p_x, BUF_SIZE * sizeof(float));\n",
    "    \n",
    "    float sum = 0.f;\n",
    "    for (int i = 0; i < BUF_SIZE; i++) {\n",
    "        sum += p_y[i] - p_x[i];\n",
    "    }\n",
    "    printf(\"Diff. Sum: %f\", sum);\n",
    "    \n",
    "    // Step 2. CUDA buffer free\n",
    "    cudaFree()\n",
    "    \n",
    "    free(p_x);\n",
    "    free(p_y);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!make buffer_alloc && ./buffer_alloc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copying Host data to GPU memory\n",
    "\n",
    "CUDA 메모리를 할당했으니 CUDA 메모리에 복사해 보도록 하겠습니다.\n",
    "\n",
    "현재로서는 아무것도 하지는 않지만, GPU가 처리할 데이터를 준비하는 과정이되는 중요한 과정입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%file cuda_memcpy.cu\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "#define BUF_SIZE 256\n",
    "\n",
    "void memcpy(float *out, float *in, size_t length) {\n",
    "    for (int i = 0; i < length / (int)sizeof(float); i++) {\n",
    "        out[i] = in[i];\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    float* p_x = (float*)malloc(BUF_SIZE * sizeof(float));\n",
    "    float* p_y = (float*)malloc(BUF_SIZE * sizeof(float));\n",
    "    \n",
    "    // Step 1. CUDA Buffer allocation\n",
    "    float *d_x, *d_y;\n",
    "    cudaMalloc((void**)&d_x, BUF_SIZE * sizeof(float));\n",
    "    cudaMalloc((void**)&d_y, BUF_SIZE * sizeof(float));\n",
    "               \n",
    "    for (int i = 0; i < BUF_SIZE; i++) {\n",
    "        p_x[i] = i * 1.5f;\n",
    "    }\n",
    "    \n",
    "    // Step 3. CUDA memcpy (Host -> Device)\n",
    "    cudaMemcpy();\n",
    "\n",
    "    // Write vector copy code\n",
    "    memcpy(p_y, p_x, BUF_SIZE * sizeof(float));\n",
    "    \n",
    "    // Step 4. CUDA memcpy (Device -> Host)\n",
    "    cudaMemcpy()\n",
    "    \n",
    "    float sum = 0.f;\n",
    "    for (int i = 0; i < BUF_SIZE; i++) {\n",
    "        sum += p_y[i] - p_x[i];\n",
    "    }\n",
    "    printf(\"Diff. Sum: %f\", sum);\n",
    "    \n",
    "    // Step 2. CUDA buffer free\n",
    "    cudaFree(d_x);\n",
    "    cudaFree(d_y);\n",
    "    \n",
    "    free(p_x);\n",
    "    free(p_y);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!make cuda_memcpy && ./cuda_memcpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Kernel Code & Call\n",
    "\n",
    "이제 GPU 함수인 Kernel 코드를 작성해보고 CPU 코드와 비교해 보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%file kernel_call.cu\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "#define BUF_SIZE 256\n",
    "\n",
    "void memcpy(float *out, float *in, size_t length) {\n",
    "    for (int i = 0; i < length / (int)sizeof(float); i++) {\n",
    "        out[i] = in[i];\n",
    "    }\n",
    "}\n",
    "\n",
    "// Step 5. Writing Kernel Code\n",
    "\n",
    "int main() {\n",
    "    float* p_x = (float*)malloc(BUF_SIZE * sizeof(float));\n",
    "    float* p_y = (float*)malloc(BUF_SIZE * sizeof(float));\n",
    "    \n",
    "    // Step 1. CUDA Buffer allocation\n",
    "    float *d_x, *d_y;\n",
    "    cudaMalloc((void**)&d_x, BUF_SIZE * sizeof(float));\n",
    "    cudaMalloc((void**)&d_y, BUF_SIZE * sizeof(float));\n",
    "               \n",
    "    for (int i = 0; i < BUF_SIZE; i++) {\n",
    "        p_x[i] = i * 1.5f;\n",
    "    }\n",
    "    \n",
    "    // Step 3. CUDA memcpy (Host -> Device)\n",
    "    cudaMemcpy(d_x, p_x, BUF_SIZE * sizeof(float), cudaMemcpyHostToDevice);\n",
    "\n",
    "    // Write vector copy code\n",
    "    memcpy(p_y, p_x, BUF_SIZE * sizeof(float));\n",
    "    \n",
    "    // Step 5. CUDA kernel call\n",
    "    \n",
    "    // Step 4. CUDA memcpy (Device -> Host)\n",
    "    cudaMemcpy(p_y, d_y, BUF_SIZE * sizeof(float), cudaMemcpyDeviceToHost);\n",
    "    \n",
    "    float sum = 0.f;\n",
    "    for (int i = 0; i < BUF_SIZE; i++) {\n",
    "        sum += p_y[i] - p_x[i];\n",
    "    }\n",
    "    printf(\"Diff. Sum: %f\", sum);\n",
    "    \n",
    "    // Step 2. CUDA buffer free\n",
    "    cudaFree(d_x);\n",
    "    cudaFree(d_y);\n",
    "    \n",
    "    free(p_x);\n",
    "    free(p_y);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!make kernel_call && ./kernel_call"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
