{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAXPY Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ y = ax + y $$\n",
    "위 연산에 대하여 벡터 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPU Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting saxpy_cpu.cc\n"
     ]
    }
   ],
   "source": [
    "%%file saxpy_cpu.cc\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include \"utils.h\"\n",
    "\n",
    "// saxpy: c = alpha * a + b\n",
    "void saxpy(float* a, float* b, float *c, float alpha, int n_size) {\n",
    "    for (int i = 0; i < n_size; i++) {\n",
    "        c[i] = alpha * a[i] + b[i];\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    float *a, *b, *c;\n",
    "    int n_size = 65536;\n",
    "    \n",
    "    init_rand();\n",
    "    \n",
    "    a = init_vector(n_size);\n",
    "    b = init_vector(n_size);\n",
    "    c = init_vector(n_size);\n",
    "    \n",
    "    printf(\"[A]\\n\");\n",
    "    print_vector(a, 100);\n",
    "    printf(\"[B]\\n\");\n",
    "    print_vector(b, 100);\n",
    "    printf(\"[C]\\n\");\n",
    "    print_vector(c, 100);\n",
    "    \n",
    "    saxpy(a, b, c, 2.0, n_size);\n",
    "    \n",
    "    printf(\"[saxpy:: c = alpha * a + b]\\n\");\n",
    "    print_vector(c, 100);\n",
    "    \n",
    "    free(a);\n",
    "    free(b);\n",
    "    free(c);\n",
    "    \n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile 및 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[A]\r\n",
      "0.22 0.07 0.03 0.89 0.01 0.23 0.85 0.99 0.37 0.26 \r\n",
      "0.06 0.25 0.51 0.85 0.66 0.12 0.80 0.87 0.94 0.11 \r\n",
      "0.69 0.42 0.63 1.00 0.93 0.55 0.24 0.62 0.76 0.20 \r\n",
      "0.46 0.98 0.28 0.49 0.88 0.29 0.72 0.73 0.28 0.09 \r\n",
      "0.98 0.34 0.34 0.49 0.19 0.00 0.61 0.99 0.87 0.56 \r\n",
      "0.10 0.57 0.98 0.73 0.56 0.91 0.28 0.80 0.53 0.04 \r\n",
      "0.01 0.99 0.02 0.28 0.48 0.89 0.57 0.20 0.62 0.86 \r\n",
      "0.29 0.61 0.19 0.64 0.10 0.38 0.64 0.71 0.37 0.51 \r\n",
      "0.27 0.47 0.08 0.25 0.20 0.64 0.16 0.48 0.44 0.68 \r\n",
      "0.52 0.45 0.67 0.53 0.73 0.15 0.43 0.30 0.35 0.05 \r\n",
      "[B]\r\n",
      "0.96 0.25 0.86 0.49 0.46 0.08 0.18 0.22 0.06 0.37 \r\n",
      "0.82 0.55 0.28 0.51 0.31 0.07 0.19 0.13 0.47 0.27 \r\n",
      "0.72 0.31 0.72 0.95 0.51 0.47 0.25 0.53 0.45 0.95 \r\n",
      "0.28 0.40 0.19 0.14 0.89 0.66 0.22 0.07 0.88 0.28 \r\n",
      "0.44 0.70 0.83 0.72 0.21 0.14 0.79 0.40 0.27 0.26 \r\n",
      "0.67 0.99 0.57 0.39 0.94 0.08 0.85 0.19 0.62 0.30 \r\n",
      "0.13 0.89 0.70 0.33 0.03 0.60 0.98 0.25 0.67 0.86 \r\n",
      "0.53 0.11 0.56 0.36 0.83 0.76 0.50 0.62 0.16 0.76 \r\n",
      "0.88 0.83 0.75 0.45 0.22 0.69 0.54 0.07 0.87 0.15 \r\n",
      "0.36 0.01 0.04 0.07 0.33 0.08 0.66 0.32 0.33 0.33 \r\n",
      "[C]\r\n",
      "0.26 0.58 0.92 0.64 0.15 0.46 0.28 0.17 0.53 0.08 \r\n",
      "0.34 0.88 0.84 0.21 0.89 0.37 0.59 0.24 0.88 0.27 \r\n",
      "0.58 0.43 0.36 0.66 0.33 0.75 0.30 0.32 0.40 0.36 \r\n",
      "0.06 0.65 0.94 0.97 0.29 0.09 0.44 0.58 0.26 0.96 \r\n",
      "0.65 0.60 0.85 0.49 0.81 0.74 0.86 0.41 0.98 0.74 \r\n",
      "0.67 0.57 0.17 0.03 0.22 0.49 0.78 0.53 0.81 0.18 \r\n",
      "0.89 0.87 0.83 0.82 0.84 0.13 0.91 0.28 0.70 0.17 \r\n",
      "0.24 0.36 0.77 0.09 0.85 0.58 0.83 0.71 0.99 0.81 \r\n",
      "0.45 0.66 0.38 0.62 0.70 0.60 0.11 0.48 0.13 0.92 \r\n",
      "0.66 0.01 0.79 0.49 0.84 0.63 0.62 0.75 0.90 0.32 \r\n",
      "[saxpy:: c = alpha * a + b]\r\n",
      "1.40 0.39 0.92 2.28 0.49 0.54 1.88 2.20 0.81 0.88 \r\n",
      "0.93 1.05 1.29 2.21 1.62 0.32 1.80 1.87 2.36 0.48 \r\n",
      "2.11 1.15 1.99 2.95 2.36 1.56 0.72 1.77 1.96 1.36 \r\n",
      "1.20 2.37 0.75 1.12 2.65 1.24 1.66 1.53 1.44 0.46 \r\n",
      "2.41 1.38 1.52 1.70 0.58 0.14 2.02 2.38 2.01 1.38 \r\n",
      "0.86 2.12 2.53 1.85 2.07 1.90 1.41 1.79 1.67 0.37 \r\n",
      "0.14 2.87 0.74 0.89 0.99 2.38 2.13 0.65 1.91 2.57 \r\n",
      "1.11 1.32 0.95 1.63 1.02 1.53 1.77 2.05 0.91 1.78 \r\n",
      "1.43 1.77 0.90 0.96 0.62 1.97 0.85 1.03 1.76 1.52 \r\n",
      "1.40 0.91 1.39 1.14 1.80 0.37 1.52 0.93 1.02 0.43 \r\n"
     ]
    }
   ],
   "source": [
    "! gcc -Wall -o saxpy_cpu saxpy_cpu.cc utils.cc && ./saxpy_cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## GPU Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting saxpy_gpu.cu\n"
     ]
    }
   ],
   "source": [
    "%%file saxpy_gpu.cu\n",
    "\n",
    "#include \"utils.h\"\n",
    "\n",
    "// CUDA Kernel function\n",
    "__global__ \n",
    "void d_saxpy(float* a, float* b, float* c, float alpha, int n_size) {\n",
    "    int i = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "    c[i] = alpha * a[i] + b[i];\n",
    "}\n",
    "\n",
    "// computation\n",
    "void saxpy(float* a, float* b, float* c, float alpha, int n_size) {\n",
    "    for (int i = 0; i < n_size; i++) {\n",
    "        c[i] = alpha * a[i] + b[i];\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    float *a, *b, *c, *cdef;\n",
    "    int n_size = 65536;\n",
    "    int bufsize= n_size * sizeof(float);\n",
    "    \n",
    "    a = init_vector(n_size);\n",
    "    b = init_vector(n_size);\n",
    "    c = init_vector(n_size);\n",
    "    cdef = init_vector(n_size);\n",
    "    \n",
    "    // Step 1. Create GPU memory\n",
    "    float *d_a, *d_b, *d_c;\n",
    "    cudaMalloc((void**)&d_a, bufsize);\n",
    "    cudaMalloc((void**)&d_b, bufsize);\n",
    "    cudaMalloc((void**)&d_c, bufsize);\n",
    "    \n",
    "    // Step 2. Copy to GPU memory\n",
    "    cudaMemcpy(d_a, a, bufsize, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_b, b, bufsize, cudaMemcpyHostToDevice);\n",
    "    cudaMemset(d_c, 0.f, bufsize);\n",
    "    \n",
    "    // Step 3. Kernel Call\n",
    "    saxpy(a, b, cdef, 2.0, n_size);\n",
    "    \n",
    "    dim3 blockDim(16);\n",
    "    dim3 gridDim((n_size + blockDim.x - 1) / blockDim.x);\n",
    "    d_saxpy<<< gridDim, blockDim >>>(d_a, d_b, d_c, 2.0, n_size);\n",
    "\n",
    "    // Step 4. Copy from GPU\n",
    "    cudaMemcpy(c, d_c, n_size * sizeof(float), cudaMemcpyDeviceToHost);\n",
    "\n",
    "    // Step 5. Check Result\n",
    "    check_result(c, cdef, n_size);\n",
    "    \n",
    "    // Step 6. Finalize GPU memory\n",
    "    cudaFree(d_a);\n",
    "    cudaFree(d_b);\n",
    "    cudaFree(d_c);\n",
    "    \n",
    "    free(a);\n",
    "    free(b);\n",
    "    free(c);\n",
    "    free(cdef);\n",
    "    \n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile 및 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete!!"
     ]
    }
   ],
   "source": [
    "! nvcc -arch=sm_30 -o saxpy_gpu saxpy_gpu.cu utils.cc && ./saxpy_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __host__ __device__의 활용\n",
    "GPU와 CPU간에 동일한 코드를 사용하게 된다면 \\__host\\__ \\__device\\__ 를 이용하는 것을 고려해 볼 수 있습니다. 이것을 이용하면 nvcc 컴파일러는 CPU와 GPU에서 모두 사용하는 코드라고 인식하여, CPU와 GPU에서 모두 사용할 수 있는 함수를 만들 수 있습니다.\n",
    "\n",
    "위 예제를 보면 SAXPY라는 동작 자체는 CPU와 GPU 모두 동일한 연산을 하고 있습니다. 따라서 하나의 함수로 통합할 수 있다면 CPU에서 검증된 알고리즘 코드를 GPU에서 쉽게 동작시켜 볼 수 있게 되고, 코드를 관리하는데도 도움이 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting saxpy_host_device.cu\n"
     ]
    }
   ],
   "source": [
    "%%file saxpy_host_device.cu\n",
    "\n",
    "#include \"utils.h\"\n",
    "\n",
    "__host__ __device__\n",
    "float _saxpy(float alpha, float a, float b) {\n",
    "    return alpha * a + b;\n",
    "}\n",
    "\n",
    "// CUDA Kernel function\n",
    "__global__ \n",
    "void d_saxpy(float* a, float* b, float* c, float alpha, int n_size) {\n",
    "    int i = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "    c[i] = _saxpy(alpha, a[i], b[i]);\n",
    "}\n",
    "\n",
    "// computation\n",
    "void saxpy(float* a, float* b, float* c, float alpha, int n_size) {\n",
    "    for (int i = 0; i < n_size; i++) {\n",
    "        c[i] = _saxpy(alpha, a[i], b[i]);\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    float *a, *b, *c, *cdef;\n",
    "    int n_size = 65536;\n",
    "    int bufsize= n_size * sizeof(float);\n",
    "    \n",
    "    a = init_vector(n_size);\n",
    "    b = init_vector(n_size);\n",
    "    c = init_vector(n_size);\n",
    "    cdef = init_vector(n_size);\n",
    "    \n",
    "    // Step 1. Create GPU memory\n",
    "    float *d_a, *d_b, *d_c;\n",
    "    cudaMalloc((void**)&d_a, bufsize);\n",
    "    cudaMalloc((void**)&d_b, bufsize);\n",
    "    cudaMalloc((void**)&d_c, bufsize);\n",
    "    \n",
    "    // Step 2. Copy to GPU memory\n",
    "    cudaMemcpy(d_a, a, bufsize, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_b, b, bufsize, cudaMemcpyHostToDevice);\n",
    "    cudaMemset(d_c, 0.f, bufsize);\n",
    "    \n",
    "    // Step 3. Kernel Call\n",
    "    saxpy(a, b, cdef, 2.0, n_size);\n",
    "    \n",
    "    dim3 blockDim(16);\n",
    "    dim3 gridDim((n_size + blockDim.x - 1) / blockDim.x);\n",
    "    d_saxpy<<< gridDim, blockDim >>>(d_a, d_b, d_c, 2.0, n_size);\n",
    "\n",
    "    // Step 4. Copy from GPU\n",
    "    cudaMemcpy(c, d_c, n_size * sizeof(float), cudaMemcpyDeviceToHost);\n",
    "\n",
    "    // Step 5. Check Result\n",
    "    check_result(c, cdef, n_size);\n",
    "    \n",
    "    // Step 6. Finalize GPU memory\n",
    "    cudaFree(d_a);\n",
    "    cudaFree(d_b);\n",
    "    cudaFree(d_c);\n",
    "    \n",
    "    free(a);\n",
    "    free(b);\n",
    "    free(c);\n",
    "    free(cdef);\n",
    "    \n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete!!"
     ]
    }
   ],
   "source": [
    "! nvcc -arch=sm_30 -o saxpy_host_device saxpy_host_device.cu utils.cc && ./saxpy_host_device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Template의 활용\n",
    "CUDA 컴파일러는 C/C++을 지원하므로 C++의 다양한 기능들을 이용할 수 있습니다. 그 중 하나는 template이 있는데요, 자료형에 따라서 커널함수를 생성할 필요가 없어진다는 장점이 있습니다. 물론 다양한 자료형을 지원하게 되는 경우 이것은 더이상 SAXPY가 아니라 DAXPY와 같이 다른 연산이 되어버리지만 개념적으로 설명을 위해 예를 들어보겠습니다.\n",
    "\n",
    "진정한 C++ 코드로 넘어가기 위해선 손대야 할 곳이 많은데요, 아래 예제 코드에서는 Kernel 함수만 바꿔서 보여드리겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting saxpy_host_device_template.cu\n"
     ]
    }
   ],
   "source": [
    "%%file saxpy_host_device_template.cu\n",
    "\n",
    "#include \"utils.h\"\n",
    "\n",
    "template <typename T>\n",
    "__host__ __device__\n",
    "T _saxpy(T alpha, T a, T b) {\n",
    "    return alpha * a + b;\n",
    "}\n",
    "\n",
    "// CUDA Kernel function\n",
    "template <typename T>\n",
    "__global__ \n",
    "void d_saxpy(T* a, T* b, T* c, T alpha, int n_size) {\n",
    "    int i = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "    c[i] = _saxpy(alpha, a[i], b[i]);\n",
    "}\n",
    "\n",
    "// computation\n",
    "template <typename T>\n",
    "void saxpy(T* a, T* b, T* c, T alpha, int n_size) {\n",
    "    for (int i = 0; i < n_size; i++) {\n",
    "        c[i] = _saxpy(alpha, a[i], b[i]);\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    float *a, *b, *c, *cdef;\n",
    "    int n_size = 65536;\n",
    "    int bufsize= n_size * sizeof(float);\n",
    "    \n",
    "    a = init_vector(n_size);\n",
    "    b = init_vector(n_size);\n",
    "    c = init_vector(n_size);\n",
    "    cdef = init_vector(n_size);\n",
    "    \n",
    "    // Step 1. Create GPU memory\n",
    "    float *d_a, *d_b, *d_c;\n",
    "    cudaMalloc((void**)&d_a, bufsize);\n",
    "    cudaMalloc((void**)&d_b, bufsize);\n",
    "    cudaMalloc((void**)&d_c, bufsize);\n",
    "    \n",
    "    // Step 2. Copy to GPU memory\n",
    "    cudaMemcpy(d_a, a, bufsize, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_b, b, bufsize, cudaMemcpyHostToDevice);\n",
    "    cudaMemset(d_c, 0.f, bufsize);\n",
    "    \n",
    "    // Step 3. Kernel Call\n",
    "    saxpy(a, b, cdef, 2.f, n_size);\n",
    "    \n",
    "    dim3 blockDim(16);\n",
    "    dim3 gridDim((n_size + blockDim.x - 1) / blockDim.x);\n",
    "    d_saxpy<<< gridDim, blockDim >>>(d_a, d_b, d_c, 2.f, n_size);\n",
    "\n",
    "    // Step 4. Copy from GPU\n",
    "    cudaMemcpy(c, d_c, n_size * sizeof(float), cudaMemcpyDeviceToHost);\n",
    "\n",
    "    // Step 5. Check Result\n",
    "    check_result(c, cdef, n_size);\n",
    "    \n",
    "    // Step 6. Finalize GPU memory\n",
    "    cudaFree(d_a);\n",
    "    cudaFree(d_b);\n",
    "    cudaFree(d_c);\n",
    "    \n",
    "    free(a);\n",
    "    free(b);\n",
    "    free(c);\n",
    "    free(cdef);\n",
    "    \n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete!!"
     ]
    }
   ],
   "source": [
    "! nvcc -arch=sm_30 -o saxpy_host_device_template saxpy_host_device_template.cu utils.cc && ./saxpy_host_device_template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utils\n",
    "다음은 위 예제 코드를 간단하게(?) 보이게 만들기 위해서 공통적으로 사용하는 기능들을 모아놓은 코드들입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting utils.h\n"
     ]
    }
   ],
   "source": [
    "%%file utils.h\n",
    "#ifndef _UTILS_H_\n",
    "#define _UTILS_H_\n",
    "\n",
    "void init_rand();\n",
    "float* init_vector(int n_size);\n",
    "void print_vector(float* p_vector, int n_size);\n",
    "void check_result(float* a, float* b, int n_size);\n",
    "\n",
    "#endif // _UTILS_H_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting utils.cc\n"
     ]
    }
   ],
   "source": [
    "%%file utils.cc\n",
    "#include <time.h>\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include \"utils.h\"\n",
    "\n",
    "void init_rand() {\n",
    "    srand (time(0));\n",
    "}\n",
    "\n",
    "float* init_vector(int n_size) {\n",
    "    // buffer create\n",
    "    float* p_vector = (float*)malloc(n_size * sizeof(float));\n",
    "    \n",
    "    // initialize vector\n",
    "    for (int i = 0; i < n_size; i++) {\n",
    "        p_vector[i] = (float)rand() / (float)(RAND_MAX);\n",
    "    }\n",
    "    \n",
    "    return p_vector;\n",
    "}\n",
    "\n",
    "void print_vector(float* p_vector, int n_size) {\n",
    "    for (int j = 0; j < n_size / 10; j++) {\n",
    "        for (int i = 0; i < 10; i++) {\n",
    "//            cout << setw(5) << fixed << setprecision( 2 ) << p_vector[10*j + i];\n",
    "            printf(\"%3.2f \", (float)p_vector[10*j + i]);\n",
    "        }\n",
    "        printf(\"\\n\");\n",
    "    }\n",
    "}\n",
    "\n",
    "void check_result(float* a, float* b, int n_size) {\n",
    "    int diff_count = 0;\n",
    "    for (int i = 0; i < n_size; i++) {\n",
    "        diff_count += a[i] != b[i] ? 1 : 0;\n",
    "    }\n",
    "    \n",
    "    if (diff_count == 0)\n",
    "        printf(\"Complete!!\");\n",
    "    else\n",
    "        printf(\"Values are mis-matching from CPU & GPU\");\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
