{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Communication Pattern for CUDA I\n",
    "\n",
    "* Map\n",
    "* Gather\n",
    "* Stencil\n",
    "* Scatter\n",
    "* Transpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%file map.cu\n",
    "\n",
    "#include <stdio.h>\n",
    "\n",
    "float* get_buffer(int n_size) {\n",
    "    return (float*)malloc(n_size * sizeof(float));\n",
    "}\n",
    "\n",
    "__global__\n",
    "void d_map(float* d_out, float* d_in, int n_size) {\n",
    "    int idx = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "    \n",
    "    d_out[idx] = d_in[idx];\n",
    "}\n",
    "\n",
    "__global__\n",
    "void d_map_shift(float* d_out, float* d_in, int n_size, int n_shift) {\n",
    "    int idx = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "    \n",
    "    d_out[(n_size + idx + n_shift) % n_size] = d_in[idx];\n",
    "}\n",
    "\n",
    "void check_result(float *p_in, float *p_out, int n_size) {\n",
    "    int compare = 0;\n",
    "    for (int i = 0; i < n_size; i++) {\n",
    "        compare += (p_in[i] - p_out[i] != 0) ? 1 : 0;\n",
    "    }\n",
    "    printf(\"Result: %d\\n\", compare);\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    float *p_in, *p_out;\n",
    "    float *d_in, *d_out;\n",
    "    \n",
    "    int n_size = 65536;\n",
    "    \n",
    "    p_in = get_buffer(n_size);\n",
    "    p_out = get_buffer(n_size);\n",
    "    \n",
    "    cudaMalloc((void**)&d_in, n_size * sizeof(float));\n",
    "    cudaMalloc((void**)&d_out, n_size * sizeof(float));\n",
    "    \n",
    "    for (int i = 0; i < n_size; i++) {\n",
    "        p_in[i] = i;\n",
    "    }\n",
    "    cudaMemcpy(d_in, p_in, n_size * sizeof(float), cudaMemcpyHostToDevice);\n",
    "    \n",
    "    dim3 blockDim(256);\n",
    "    dim3 gridDim((n_size + blockDim.x - 1) / blockDim.x);\n",
    "    d_map<<<gridDim, blockDim>>>(d_out, d_in, n_size);\n",
    "    \n",
    "    cudaMemcpy(p_out, d_out, n_size * sizeof(float), cudaMemcpyDeviceToHost);\n",
    "    \n",
    "    check_result(p_in, p_out, n_size);\n",
    "    \n",
    "    d_map_shift<<<gridDim, blockDim>>>(d_out, d_in, n_size, 2);\n",
    "    cudaMemcpy(p_out, d_out, n_size * sizeof(float), cudaMemcpyDeviceToHost);\n",
    "    \n",
    "    check_result(p_in, p_out, n_size);\n",
    "    \n",
    "    cudaFree(d_in);\n",
    "    cudaFree(d_out);\n",
    "    \n",
    "    free(p_in);\n",
    "    free(p_out);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! make map\n",
    "! ./map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2/3. Gather & Stencil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%file gather.cu\n",
    "\n",
    "#include <stdio.h>\n",
    "\n",
    "const int n_size = 1024;\n",
    "\n",
    "float* get_buffer(int n_size) {\n",
    "    return (float*)malloc(n_size * sizeof(float));\n",
    "}\n",
    "\n",
    "void gather_sum(float* p_out, float* p_in, int n_size, int n_width) {\n",
    "    for (int j = 0; j < n_size; j++) {\n",
    "        float sum = 0.0;\n",
    "        for (int i = 0; i < n_width; i++) {\n",
    "            int input_idx = j + i;\n",
    "        \n",
    "            if (input_idx >= n_size) {\n",
    "                input_idx %= n_size;\n",
    "            }\n",
    "\n",
    "            sum += p_in[input_idx];\n",
    "        }\n",
    "        p_out[j] = sum;\n",
    "    }\n",
    "}\n",
    "\n",
    "__global__\n",
    "void d_gather_sum(float* d_out, float* d_in, int n_size, int n_width) {\n",
    "    int idx = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "    \n",
    "    float sum = 0.0;\n",
    "    for (int i = 0; i < n_width; i++) {\n",
    "        int input_idx = idx + i;\n",
    "        \n",
    "        if (input_idx >= n_size) {\n",
    "            input_idx %= n_size;\n",
    "        }\n",
    "        \n",
    "        sum += d_in[input_idx];\n",
    "    }\n",
    "    d_out[idx] = sum;\n",
    "}\n",
    "\n",
    "void check_result(float *p_out, float *p_out_host, int n_size) {\n",
    "    float compare = 0.0;\n",
    "    \n",
    "    for (int i = 0; i < n_size; i++) {\n",
    "        compare += (p_out[i] - p_out_host[i] != 0) ? 1 : 0;\n",
    "    }\n",
    "    \n",
    "    printf(\"Result: %f\\n\", compare);\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    float *p_in, *p_out, *p_out_host;\n",
    "    float *d_in, *d_out;\n",
    "    int n_width = 3;\n",
    "    \n",
    "    p_in = get_buffer(n_size);\n",
    "    p_out = get_buffer(n_size);\n",
    "    p_out_host = get_buffer(n_size);\n",
    "    \n",
    "    cudaMalloc((void**)&d_in, n_size * sizeof(float));\n",
    "    cudaMalloc((void**)&d_out, n_size * sizeof(float));\n",
    "    \n",
    "    for (int i = 0; i < 1024; i++) {\n",
    "        p_in[i] = i;\n",
    "    }\n",
    "    cudaMemcpy(d_in, p_in, n_size * sizeof(float), cudaMemcpyHostToDevice);\n",
    "    \n",
    "    gather_sum(p_out_host, p_in, n_size, n_width);\n",
    "    \n",
    "    dim3 blockDim(256);\n",
    "    dim3 gridDim((n_size + blockDim.x - 1) / blockDim.x);\n",
    "    d_gather_sum<<<gridDim, blockDim>>>(d_out, d_in, n_size, n_width);\n",
    "    \n",
    "    cudaMemcpy(p_out, d_out, n_size * sizeof(float), cudaMemcpyDeviceToHost);\n",
    "    \n",
    "    check_result(p_out, p_out_host, n_size);\n",
    "    \n",
    "    cudaFree(d_in);\n",
    "    cudaFree(d_out);\n",
    "    \n",
    "    free(p_in);\n",
    "    free(p_out);\n",
    "    free(p_out_host);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! make gather\n",
    "! ./gather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%file scatter.cu\n",
    "\n",
    "#include <stdio.h>\n",
    "\n",
    "const int n_size = 1024;\n",
    "const int n_scatter = 3;\n",
    "\n",
    "float* get_buffer(int n_size) {\n",
    "    return (float*)malloc(n_size * sizeof(float));\n",
    "}\n",
    "\n",
    "void scatter(float* p_out, float* p_in, int n_size, int n_scatter) {\n",
    "    for (int j = 0; j < n_size; j++) {\n",
    "        for (int i = 0; i < n_scatter; i++) {\n",
    "            p_out[i * n_size + j] = j;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "__global__\n",
    "void d_scatter(float* d_out, float* d_in, int n_size, int n_scatter) {\n",
    "    int idx = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "    \n",
    "    for (int i = 0; i < n_scatter; i++) {\n",
    "        d_out[i * n_size + idx] = idx;\n",
    "    }\n",
    "}\n",
    "\n",
    "void check_result(float *p_out, float *p_out_host, int n_size, int n_scatter) {\n",
    "    float compare = 0.0;\n",
    "    \n",
    "    for (int i = 0; i < n_size * n_scatter; i++) {\n",
    "        compare += (p_out[i] - p_out_host[i] != 0) ? 1 : 0;\n",
    "    }\n",
    "    \n",
    "    printf(\"Result: %f\\n\", compare);\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    float *p_in, *p_out, *p_out_host;\n",
    "    float *d_in, *d_out;\n",
    "    \n",
    "    p_in = get_buffer(n_size);\n",
    "    p_out = get_buffer(n_size * n_scatter);\n",
    "    p_out_host = get_buffer(n_size * n_scatter);\n",
    "    \n",
    "    cudaMalloc((void**)&d_in, n_size * sizeof(float));\n",
    "    cudaMalloc((void**)&d_out, n_size * n_scatter * sizeof(float));\n",
    "    \n",
    "    for (int i = 0; i < n_size; i++) {\n",
    "        p_in[i] = i;\n",
    "    }\n",
    "    cudaMemcpy(d_in, p_in, n_size * sizeof(float), cudaMemcpyHostToDevice);\n",
    "    \n",
    "    scatter(p_out_host, p_in, n_size, n_scatter);\n",
    "    \n",
    "    dim3 blockDim(256);\n",
    "    dim3 gridDim((n_size + blockDim.x - 1) / blockDim.x);\n",
    "    d_scatter<<<gridDim, blockDim>>>(d_out, d_in, n_size, n_scatter);\n",
    "    \n",
    "    cudaMemcpy(p_out, d_out, n_size * n_scatter * sizeof(float), cudaMemcpyDeviceToHost);\n",
    "    \n",
    "    check_result(p_out, p_out_host, n_size, n_scatter);\n",
    "    \n",
    "    cudaFree(d_in);\n",
    "    cudaFree(d_out);\n",
    "    \n",
    "    free(p_in);\n",
    "    free(p_out);\n",
    "    free(p_out_host);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! make scatter\n",
    "! ./scatter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%file transpose.cu\n",
    "\n",
    "#include <stdio.h>\n",
    "\n",
    "float* get_buffer(int n_size) {\n",
    "    return (float*)malloc(n_size * sizeof(float));\n",
    "}\n",
    "\n",
    "void check_result(float *p_out, float *p_out_cuda, int n_size) {\n",
    "    int count = 0;\n",
    "    \n",
    "    for (int i = 0; i < n_size; i++) {\n",
    "        if (p_out[i] - p_out_cuda[i] != 0.0) {\n",
    "            count++;\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    printf(\"Result: %d\\n\", count);\n",
    "}\n",
    "\n",
    "void transpose(float *p_out, float *p_in, int n_width, int n_height) {\n",
    "    for (int j = 0; j < n_height; j++) {\n",
    "        for (int i = 0; i < n_width; i++) {\n",
    "            p_out[i * n_height + j] = p_in[j * n_width + i];\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "__global__ \n",
    "void d_transpose(float *d_out, float *d_in, int n_width, int n_height) {\n",
    "    int idx_x = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "    int idx_y = blockDim.y * blockIdx.y + threadIdx.y;\n",
    "    \n",
    "    if (idx_x < n_width && idx_y < n_height)\n",
    "        d_out[idx_x * n_height + idx_y] = d_in[idx_y * n_width + idx_x];\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    float *p_in, *p_out, *p_out_cuda;\n",
    "    float *d_in, *d_out;\n",
    "    \n",
    "    int n_width = 1920;\n",
    "    int n_height = 1080;\n",
    "    \n",
    "    p_in = get_buffer(n_width * n_height);\n",
    "    p_out = get_buffer(n_width * n_height);\n",
    "    p_out_cuda = get_buffer(n_width * n_height);\n",
    "    \n",
    "    // Step 1. Allocate to GPU memory\n",
    "    cudaMalloc((void**)&d_in, n_width * n_height * sizeof(float));\n",
    "    cudaMalloc((void**)&d_out, n_width * n_height * sizeof(float));\n",
    "    \n",
    "    // Initialize input data\n",
    "    for (int j = 0; j < n_height; j++) {\n",
    "        for (int i = 0; i < n_width; i++) {\n",
    "            p_in[j * n_width + i] = float(j * n_width + i);\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    // Step 2. Copy to GPU memory\n",
    "    cudaMemcpy(d_in, p_in, n_width * n_height * sizeof(float), cudaMemcpyHostToDevice);\n",
    "    \n",
    "    transpose(p_out, p_in, n_width, n_height);\n",
    "    \n",
    "    // Step 3. Kernel leaunch\n",
    "    dim3 blockDim(16, 16);\n",
    "    dim3 gridDim((n_width + blockDim.x - 1) / blockDim.x, (n_height + blockDim.y - 1) / blockDim.y);\n",
    "    d_transpose<<<gridDim, blockDim>>>(d_out, d_in, n_width, n_height);\n",
    "    \n",
    "    // Step 4. Copy from GPU\n",
    "    cudaMemcpy(p_out_cuda, d_out, n_width * n_height * sizeof(float), cudaMemcpyDeviceToHost);\n",
    "    \n",
    "    // Step 5. check result\n",
    "    check_result(p_out, p_out_cuda, n_width * n_height);\n",
    "    \n",
    "    // Step 6. free GPU memory\n",
    "    cudaFree(d_in);\n",
    "    cudaFree(d_out);\n",
    "    \n",
    "    free(p_in);\n",
    "    free(p_out);\n",
    "    free(p_out_cuda);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! make transpose\n",
    "! ./transpose"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
