{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization\n",
    "## 2. Pinned Memory\n",
    "\n",
    "Pinned Memory는 DMA Operation을 통해 데이터를 전송할 수 있도록 해주는 메모리 공간을 말합니다. CPU/GPU 데이터 전송에서 CPU가 동작하지 않으므로 점유율이 낮고, PCI Express의 대역폭을 최대한 사용할 수 있다는 장점이 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sgemm_pinned_memory.cu\n"
     ]
    }
   ],
   "source": [
    "%%file sgemm_pinned_memory.cu\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <time.h>\n",
    "#include <helper_cuda.h>\n",
    "\n",
    "typedef enum TARGET {HOST, DEVICE} TARGET;\n",
    "\n",
    "typedef struct {\n",
    "    int width;\n",
    "    int height;\n",
    "    float *elements;\n",
    "} Matrix;\n",
    "\n",
    "__global__ void sgemm(Matrix A, Matrix B, Matrix C, \n",
    "                      const float alpha, const float beta, \n",
    "                      const int width, const int height) {\n",
    "    int idx_x = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "    int idx_y = blockDim.y * blockIdx.y + threadIdx.y;\n",
    "    int idx = idx_y * width + idx_x;\n",
    "    \n",
    "    if (idx_x >= width || idx_y >= height)\n",
    "        return;\n",
    "    \n",
    "    float value = 0.f;\n",
    "    for (int e = 0; e < width; e++)\n",
    "        value += A.elements[idx_y * width + e] * B.elements[e * width + idx_x];\n",
    "    C.elements[idx] = alpha * value + beta * C.elements[idx];\n",
    "}\n",
    "\n",
    "void InitMatrix(Matrix &mat, const int width, const int height, TARGET target = HOST);\n",
    "\n",
    "int main(int argv, char* argc[]) {\n",
    "    Matrix A, B, C_host, C_device;\n",
    "    Matrix dA, dB, dC;\n",
    "    const float alpha = 2.f;\n",
    "    const float beta = .5f;\n",
    "    const int width = 2048;\n",
    "    const int height = 2048;\n",
    "    float elapsed_gpu;\n",
    "    double elapsed_cpu;\n",
    "    \n",
    "    // CUDA Event Create to estimate elased time\n",
    "    cudaEvent_t start, stop;\n",
    "    struct timespec begin, finish;\n",
    "    \n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    \n",
    "    // Initialize host matrix\n",
    "    InitMatrix(A, width, height);\n",
    "    InitMatrix(B, width, height);\n",
    "    InitMatrix(C_device, width, height);\n",
    "    \n",
    "    // CUDA Memory Initialize\n",
    "    InitMatrix(dA, width, height, DEVICE);\n",
    "    InitMatrix(dB, width, height, DEVICE);\n",
    "    InitMatrix(dC, width, height, DEVICE);\n",
    "    \n",
    "    // CUDA Operation\n",
    "    cudaEventRecord(start, 0);\n",
    "    clock_gettime(CLOCK_MONOTONIC, &begin);\n",
    "    \n",
    "    // Copy host data to the device (CUDA global memory)\n",
    "    cudaMemcpy(dA.elements, A.elements, width * height * sizeof(float), cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(dB.elements, B.elements, width * height * sizeof(float), cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(dC.elements, C_device.elements, width * height * sizeof(float), cudaMemcpyHostToDevice);\n",
    "    \n",
    "    // Launch GPU Kernel\n",
    "    dim3 blockDim(16, 16);\n",
    "    dim3 gridDim((width + blockDim.x - 1) / blockDim.x, (height + blockDim.y - 1) / blockDim.y);\n",
    "    sgemm<<<gridDim, blockDim>>>(dA, dB, dC, alpha, beta, width, height);\n",
    "    \n",
    "    // Copy computation result from the Device the host memory\n",
    "    cudaMemcpy(C_device.elements, dC.elements, width * height * sizeof(float), cudaMemcpyDeviceToHost);\n",
    "    \n",
    "    clock_gettime(CLOCK_MONOTONIC, &finish);\n",
    "    cudaEventRecord(stop, 0);\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    // Estimate CUDA operation time\n",
    "    cudaEventRecord(stop, 0);\n",
    "    cudaEventSynchronize(stop);\n",
    "    \n",
    "    cudaEventElapsedTime(&elapsed_gpu, start, stop);\n",
    "    printf(\"SGEMM CUDA Elapsed time: %f ms\\n\", elapsed_gpu);\n",
    "    elapsed_cpu = (finish.tv_sec - begin.tv_sec);\n",
    "    elapsed_cpu += (finish.tv_nsec - begin.tv_nsec) / 1000000000.0;\n",
    "    printf(\"Host time: %f ms\\n\", elapsed_cpu * 1000);\n",
    "    \n",
    "    // finalize CUDA event\n",
    "    cudaEventDestroy(start);\n",
    "    cudaEventDestroy(stop);\n",
    "    \n",
    "    // Finalize\n",
    "    cudaFree(dA.elements);\n",
    "    cudaFree(dB.elements);\n",
    "    cudaFree(dC.elements);\n",
    "    \n",
    "    cudaFreeHost(A.elements);\n",
    "    cudaFreeHost(B.elements);\n",
    "    cudaFreeHost(C_device.elements);\n",
    "    \n",
    "    return 0;\n",
    "}\n",
    "\n",
    "void InitMatrix(Matrix &mat, const int width, const int height, TARGET target) {\n",
    "    mat.width = width;\n",
    "    mat.height = height;\n",
    "    \n",
    "    if (target == DEVICE) {\n",
    "        cudaMalloc((void**)&mat.elements, width * height * sizeof(float));\n",
    "    }\n",
    "    else {\n",
    "        checkCudaErrors(cudaHostAlloc(&mat.elements, width * height * sizeof(float), cudaHostAllocDefault));\n",
    "\n",
    "        for (int row = 0; row < height; row++) {\n",
    "            for (int col = 0; col < width; col++) {\n",
    "                mat.elements[row * width + col] = row * width + col * 0.001;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc sgemm_pinned_memory.cu --ptxas-options=--verbose -gencode=arch=compute_35,code=sm_35 -I/usr/local/cuda/samples/common/inc -o sgemm_pinned_memory\n",
      "sgemm_pinned_memory.cu(34): warning: variable \"C_host\" was declared but never referenced\n",
      "\n",
      "sgemm_pinned_memory.cu(34): warning: variable \"C_host\" was declared but never referenced\n",
      "\n",
      "ptxas info    : 0 bytes gmem\n",
      "ptxas info    : Compiling entry function '_Z5sgemm6MatrixS_S_ffii' for 'sm_35'\n",
      "ptxas info    : Function properties for _Z5sgemm6MatrixS_S_ffii\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 17 registers, 384 bytes cmem[0]\n"
     ]
    }
   ],
   "source": [
    "! make sgemm_pinned_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGEMM CUDA Elapsed time: 6.507008 ms\r\n",
      "Host time: 6.494357 ms\r\n"
     ]
    }
   ],
   "source": [
    "! ./sgemm_pinned_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
