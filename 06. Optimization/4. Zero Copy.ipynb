{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Zero copy\n",
    "\n",
    "Zero-copy를 이용하시면, Pinned memory를 사용하는 한편 명시적으로 GPU memory를 할당하고, 복사하는 과정을 생략하고, GPU Kernel에서 Host memory에 접근하는 것과 같은 효과를 가져올 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sgemm_zero_copy.cu\n"
     ]
    }
   ],
   "source": [
    "%%file sgemm_zero_copy.cu\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <time.h>\n",
    "#include <helper_cuda.h>\n",
    "\n",
    "typedef enum TARGET {HOST, DEVICE} TARGET;\n",
    "\n",
    "typedef struct {\n",
    "    int width;\n",
    "    int height;\n",
    "    float *elements;\n",
    "} Matrix;\n",
    "\n",
    "__global__ void sgemm(Matrix A, Matrix B, Matrix C, \n",
    "                      const float alpha, const float beta, \n",
    "                      const int width, const int height) {\n",
    "    int idx_x = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "    int idx_y = blockDim.y * blockIdx.y + threadIdx.y;\n",
    "    int idx = idx_y * width + idx_x;\n",
    "    \n",
    "    if (idx_x >= width || idx_y >= height)\n",
    "        return;\n",
    "    \n",
    "    float value = 0.f;\n",
    "    for (int e = 0; e < width; e++)\n",
    "        value += A.elements[idx_y * width + e] * B.elements[e * width + idx_x];\n",
    "    C.elements[idx] = alpha * value + beta * C.elements[idx];\n",
    "}\n",
    "\n",
    "void InitMatrix(Matrix &mat, const int width, const int height, TARGET target = HOST);\n",
    "\n",
    "int main(int argv, char* argc[]) {\n",
    "    Matrix A, B, C;\n",
    "    Matrix dA, dB, dC;\n",
    "    const float alpha = 2.f;\n",
    "    const float beta = .5f;\n",
    "    const int width = 2048;\n",
    "    const int height = width;\n",
    "    float elapsed_gpu;\n",
    "    double elapsed_cpu;\n",
    "    \n",
    "    // CUDA Event Create to estimate elased time\n",
    "    cudaEvent_t start, stop;\n",
    "    struct timespec begin, finish;\n",
    "    \n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    \n",
    "    // Initialize host matrix\n",
    "    InitMatrix(A, width, height);\n",
    "    InitMatrix(B, width, height);\n",
    "    InitMatrix(C, width, height);\n",
    "    \n",
    "    // CUDA Memory Initialize\n",
    "    cudaHostGetDevicePointer((void**)&dA.elements, A.elements, 0);\n",
    "    cudaHostGetDevicePointer((void**)&dB.elements, B.elements, 0);\n",
    "    cudaHostGetDevicePointer((void**)&dC.elements, C.elements, 0);\n",
    "    \n",
    "    // CUDA Operation\n",
    "    cudaEventRecord(start, 0);\n",
    "    clock_gettime(CLOCK_MONOTONIC, &begin);\n",
    "    \n",
    "    // Copy host data to the device (CUDA global memory) YOU DON'T NEED THIS\n",
    "    //cudaMemcpy(dA.elements, A.elements, width * height * sizeof(float), cudaMemcpyHostToDevice);\n",
    "    //cudaMemcpy(dB.elements, B.elements, width * height * sizeof(float), cudaMemcpyHostToDevice);\n",
    "    //cudaMemcpy(dC.elements, C.elements, width * height * sizeof(float), cudaMemcpyHostToDevice);\n",
    "    \n",
    "    // Launch GPU Kernel\n",
    "    dim3 blockDim(16, 16);\n",
    "    dim3 gridDim((width + blockDim.x - 1) / blockDim.x, (height + blockDim.y - 1) / blockDim.y);\n",
    "    sgemm<<<gridDim, blockDim>>>(dA, dB, dC, alpha, beta, width, height);\n",
    "    cudaEventRecord(stop, 0);\n",
    "    \n",
    "    // Copy computation result from the Device the host memory\n",
    "    //cudaMemcpy(C.elements, dC.elements, width * height * sizeof(float), cudaMemcpyDeviceToHost);\n",
    "    \n",
    "    clock_gettime(CLOCK_MONOTONIC, &finish);\n",
    "    \n",
    "    // Estimate CUDA operation time\n",
    "    cudaEventSynchronize(stop);\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    cudaEventElapsedTime(&elapsed_gpu, start, stop);\n",
    "    printf(\"SGEMM CUDA Elapsed time: %f ms\\n\", elapsed_gpu);\n",
    "    elapsed_cpu = (finish.tv_sec - begin.tv_sec);\n",
    "    elapsed_cpu += (finish.tv_nsec - begin.tv_nsec) / 1000000000.0;\n",
    "    printf(\"Host time: %f ms\\n\", elapsed_cpu * 1000);\n",
    "    \n",
    "    // finalize CUDA event\n",
    "    cudaEventDestroy(start);\n",
    "    cudaEventDestroy(stop);\n",
    "    \n",
    "    // Finalize\n",
    "    //cudaFree(dA.elements);\n",
    "    //cudaFree(dB.elements);\n",
    "    //cudaFree(dC.elements);\n",
    "    \n",
    "    cudaFreeHost(A.elements);\n",
    "    cudaFreeHost(B.elements);\n",
    "    cudaFreeHost(C.elements);\n",
    "    \n",
    "    return 0;\n",
    "}\n",
    "\n",
    "void InitMatrix(Matrix &mat, const int width, const int height, TARGET target) {\n",
    "    mat.width = width;\n",
    "    mat.height = height;\n",
    "    \n",
    "    if (target == DEVICE) {\n",
    "        cudaMalloc((void**)&mat.elements, width * height * sizeof(float));\n",
    "    }\n",
    "    else {\n",
    "        checkCudaErrors(cudaHostAlloc(&mat.elements, width * height * sizeof(float), cudaHostAllocMapped));\n",
    "\n",
    "        for (int row = 0; row < height; row++) {\n",
    "            for (int col = 0; col < width; col++) {\n",
    "                mat.elements[row * width + col] = row * width + col * 0.001;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc sgemm_zero_copy.cu --ptxas-options=--verbose -gencode=arch=compute_35,code=sm_35 -I/usr/local/cuda/samples/common/inc -o sgemm_zero_copy\n",
      "ptxas info    : 0 bytes gmem\n",
      "ptxas info    : Compiling entry function '_Z5sgemm6MatrixS_S_ffii' for 'sm_35'\n",
      "ptxas info    : Function properties for _Z5sgemm6MatrixS_S_ffii\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 17 registers, 384 bytes cmem[0]\n"
     ]
    }
   ],
   "source": [
    "! make sgemm_zero_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGEMM CUDA Elapsed time: 0.020896 ms\r\n",
      "Host time: 0.018359 ms\r\n"
     ]
    }
   ],
   "source": [
    "! ./sgemm_zero_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Zero-copy를 사용했을 때, 보다 빠른 수행시간을 보였습니다. 이는 Kernel 실행이 GPU 메모리 복사가 끝나기까지 기다려야하"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
